#!/usr/bin/env python3
"""
PostgreSQL Migration Runner for v0.3.0
é•·æœŸè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import asyncpg
import os
import logging
from pathlib import Path
from typing import Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def run_migration(postgres_url: str, migration_file: Path) -> bool:
    """
    ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ
    
    Args:
        postgres_url: PostgreSQLæ¥ç¶šURL
        migration_file: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        å®Ÿè¡ŒæˆåŠŸ/å¤±æ•—
    """
    try:
        logger.info(f"ğŸ”„ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹: {migration_file.name}")
        
        # PostgreSQLæ¥ç¶š
        conn = await asyncpg.connect(postgres_url)
        
        try:
            # SQLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            sql_content = migration_file.read_text(encoding='utf-8')
            
            # SQLã‚’å®Ÿè¡Œï¼ˆè¤‡æ•°ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆå¯¾å¿œï¼‰
            await conn.execute(sql_content)
            
            logger.info(f"âœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {migration_file.name}")
            return True
            
        finally:
            await conn.close()
            
    except Exception as e:
        logger.error(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {migration_file.name} - {e}")
        return False


async def check_database_connection(postgres_url: str) -> bool:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹")
        conn = await asyncpg.connect(postgres_url)
        
        # åŸºæœ¬ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        result = await conn.fetchval("SELECT 1")
        await conn.close()
        
        if result == 1:
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ")
            return True
        else:
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def check_pgvector_extension() -> bool:
    """pgvectoræ‹¡å¼µã®ç¢ºèª"""
    postgres_url = os.getenv('POSTGRESQL_URL')
    if not postgres_url:
        logger.error("âŒ POSTGRESQL_URLç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
        
    try:
        conn = await asyncpg.connect(postgres_url)
        
        # pgvectoræ‹¡å¼µã®å­˜åœ¨ç¢ºèª
        result = await conn.fetchval("""
            SELECT EXISTS(
                SELECT 1 FROM pg_extension WHERE extname = 'vector'
            )
        """)
        
        await conn.close()
        
        if result:
            logger.info("âœ… pgvectoræ‹¡å¼µãŒåˆ©ç”¨å¯èƒ½")
            return True
        else:
            logger.warning("âš ï¸ pgvectoræ‹¡å¼µãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            logger.info("ğŸ’¡ æ‹¡å¼µã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰: CREATE EXTENSION vector;")
            return False
            
    except Exception as e:
        logger.error(f"âŒ pgvectorç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
    
    # ç’°å¢ƒå¤‰æ•°ç¢ºèª
    postgres_url = os.getenv('POSTGRESQL_URL')
    if not postgres_url:
        logger.error("âŒ POSTGRESQL_URLç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆå–å¾—
    project_root = Path(__file__).parent.parent
    migrations_dir = project_root / "migrations"
    
    if not migrations_dir.exists():
        logger.error(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {migrations_dir}")
        return False
    
    logger.info("ğŸš€ PostgreSQL ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œé–‹å§‹")
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
    if not await check_database_connection(postgres_url):
        return False
    
    # 2. pgvectoræ‹¡å¼µç¢ºèª
    await check_pgvector_extension()
    
    # 3. ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè¡Œ
    migration_files = sorted(migrations_dir.glob("*.sql"))
    
    if not migration_files:
        logger.warning("âš ï¸ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    success_count = 0
    total_count = len(migration_files)
    
    for migration_file in migration_files:
        success = await run_migration(postgres_url, migration_file)
        if success:
            success_count += 1
        else:
            logger.error(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­æ–­: {migration_file.name}")
            break
    
    # 4. çµæœå ±å‘Š
    if success_count == total_count:
        logger.info(f"ğŸ‰ å…¨ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {success_count}/{total_count}")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆç¢ºèª
        await verify_table_creation(postgres_url)
        return True
    else:
        logger.error(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨åˆ†å¤±æ•—: {success_count}/{total_count}")
        return False


async def verify_table_creation(postgres_url: str):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆç¢ºèª"""
    try:
        conn = await asyncpg.connect(postgres_url)
        
        # unified_memoriesãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        table_exists = await conn.fetchval("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'unified_memories'
            )
        """)
        
        if table_exists:
            # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
            columns = await conn.fetch("""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_schema = 'public' 
                AND table_name = 'unified_memories'
                ORDER BY ordinal_position
            """)
            
            logger.info(f"âœ… unified_memoriesãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆç¢ºèª: {len(columns)}ã‚«ãƒ©ãƒ ")
            for col in columns:
                logger.info(f"  - {col['column_name']}: {col['data_type']}")
                
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
            indexes = await conn.fetch("""
                SELECT indexname 
                FROM pg_indexes 
                WHERE tablename = 'unified_memories'
            """)
            
            logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆç¢ºèª: {len(indexes)}å€‹")
            for idx in indexes:
                logger.info(f"  - {idx['indexname']}")
        else:
            logger.error("âŒ unified_memoriesãƒ†ãƒ¼ãƒ–ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        await conn.close()
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")


def sync_main():
    """åŒæœŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    return asyncio.run(main())


if __name__ == "__main__":
    import sys
    
    print("ğŸ—„ï¸ PostgreSQL Migration Runner v0.3.0")
    print("=" * 50)
    
    success = sync_main()
    
    if success:
        print("\nğŸ‰ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸï¼v0.3.0é•·æœŸè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†")
        sys.exit(0)
    else:
        print("\nâŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—ã€‚ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        sys.exit(1)