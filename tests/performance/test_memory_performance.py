"""
Memory System Performance Tests - TDD Phase 10

ãƒ†ã‚¹ãƒˆå¯¾è±¡: Memory Systemæ€§èƒ½è¦ä»¶
ç›®çš„: Hot Memory <0.1ç§’, Cold Memory <3.0ç§’æ€§èƒ½æ¤œè¨¼
"""

import pytest
import pytest_asyncio
import asyncio
import time
import statistics
import os
from typing import List, Dict, Any
from datetime import datetime

from src.infrastructure.memory_system import ImprovedDiscordMemorySystem as DiscordMemorySystem


class TestMemoryPerformanceBenchmarks:
    """Memory Systemæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
    
    @pytest_asyncio.fixture
    async def performance_memory_system(self):
        """æ€§èƒ½ãƒ†ã‚¹ãƒˆç”¨Memory System"""
        system = DiscordMemorySystem(
            redis_url="redis://localhost:6379/14",  # æ€§èƒ½ãƒ†ã‚¹ãƒˆå°‚ç”¨DB
            postgres_url="postgresql://discord_agent:discord_agent_password@localhost:5432/discord_agent",
            gemini_api_key=os.getenv('GEMINI_API_KEY', 'test_key')
        )
        
        # åˆæœŸåŒ–
        initialized = await system.initialize()
        if not initialized:
            pytest.skip("Memory system initialization failed")
        
        yield system
        await system.cleanup()
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_hot_memory_load_performance_target(self, performance_memory_system):
        """Hot Memoryèª­ã¿è¾¼ã¿æ€§èƒ½ãƒ†ã‚¹ãƒˆ: ç›®æ¨™0.1ç§’ä»¥å†…"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled. Set PERFORMANCE_TESTS_ENABLED=1")
        
        memory_system = performance_memory_system
        test_channel = "hot_performance_test"
        
        # äº‹å‰ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        for i in range(20):  # æœ€å¤§å®¹é‡ã¾ã§è¿½åŠ 
            await memory_system.update_memory({
                'messages': [{'role': 'user', 'content': f'æ€§èƒ½ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}'}],
                'selected_agent': 'performance_agent',
                'response_content': f'æ€§èƒ½ãƒ†ã‚¹ãƒˆå¿œç­”{i}',
                'channel_id': test_channel,
                'confidence': 0.85
            })
        
        # æ€§èƒ½æ¸¬å®š (100å›å®Ÿè¡Œ)
        execution_times = []
        
        for _ in range(100):
            start_time = time.perf_counter()
            
            result = await memory_system.load_hot_memory(test_channel)
            
            end_time = time.perf_counter()
            execution_time = end_time - start_time
            execution_times.append(execution_time)
            
            # çµæœç¢ºèª
            assert len(result) <= 20
        
        # çµ±è¨ˆè¨ˆç®—
        avg_time = statistics.mean(execution_times)
        median_time = statistics.median(execution_times)
        p95_time = statistics.quantiles(execution_times, n=20)[18]  # 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
        max_time = max(execution_times)
        
        # æ€§èƒ½è¦ä»¶ç¢ºèª
        assert avg_time < 0.1, f"Hot Memoryå¹³å‡å¿œç­”æ™‚é–“ç›®æ¨™æœªé”: {avg_time:.4f}s > 0.1s"
        assert p95_time < 0.1, f"Hot Memory 95%å¿œç­”æ™‚é–“ç›®æ¨™æœªé”: {p95_time:.4f}s > 0.1s"
        
        # æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ
        print(f"\nğŸ“Š Hot Memory Performance Report:")
        print(f"   å¹³å‡å¿œç­”æ™‚é–“: {avg_time:.4f}s")
        print(f"   ä¸­å¤®å€¤å¿œç­”æ™‚é–“: {median_time:.4f}s") 
        print(f"   95%å¿œç­”æ™‚é–“: {p95_time:.4f}s")
        print(f"   æœ€å¤§å¿œç­”æ™‚é–“: {max_time:.4f}s")
        print(f"   âœ… ç›®æ¨™é”æˆ: <0.1ç§’")
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_hot_memory_update_performance_target(self, performance_memory_system):
        """Hot Memoryæ›´æ–°æ€§èƒ½ãƒ†ã‚¹ãƒˆ: ç›®æ¨™0.1ç§’ä»¥å†…"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled")
        
        memory_system = performance_memory_system
        test_channel = "hot_update_performance_test"
        
        # æ€§èƒ½æ¸¬å®š (50å›å®Ÿè¡Œ)
        execution_times = []
        
        for i in range(50):
            conversation_data = {
                'messages': [{'role': 'user', 'content': f'æ›´æ–°æ€§èƒ½ãƒ†ã‚¹ãƒˆ{i}'}],
                'selected_agent': 'update_test_agent',
                'response_content': f'æ›´æ–°å¿œç­”{i}',
                'channel_id': test_channel,
                'confidence': 0.9
            }
            
            start_time = time.perf_counter()
            
            result = await memory_system.update_memory(conversation_data)
            
            end_time = time.perf_counter()
            execution_time = end_time - start_time
            execution_times.append(execution_time)
            
            assert result is True
        
        # çµ±è¨ˆè¨ˆç®—
        avg_time = statistics.mean(execution_times)
        p95_time = statistics.quantiles(execution_times, n=20)[18]
        
        # æ€§èƒ½è¦ä»¶ç¢ºèª (æ›´æ–°ã¯å¤šå°‘ä½™è£•ã‚’æŒãŸã›ã¦0.15ç§’)
        assert avg_time < 0.15, f"Hot Memoryæ›´æ–°å¹³å‡æ™‚é–“ç›®æ¨™æœªé”: {avg_time:.4f}s > 0.15s"
        
        print(f"\nğŸ“Š Hot Memory Update Performance Report:")
        print(f"   å¹³å‡æ›´æ–°æ™‚é–“: {avg_time:.4f}s")
        print(f"   95%æ›´æ–°æ™‚é–“: {p95_time:.4f}s")
        print(f"   âœ… ç›®æ¨™é”æˆ: <0.15ç§’")
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_cold_memory_search_performance_target(self, performance_memory_system):
        """Cold Memoryæ¤œç´¢æ€§èƒ½ãƒ†ã‚¹ãƒˆ: ç›®æ¨™3.0ç§’ä»¥å†…"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled")
        
        if not os.getenv('GEMINI_API_KEY'):
            pytest.skip("GEMINI_API_KEY required for embedding generation")
        
        memory_system = performance_memory_system
        
        # æ€§èƒ½æ¸¬å®š (10å›å®Ÿè¡Œ - APIåˆ¶é™è€ƒæ…®)
        execution_times = []
        search_queries = [
            "Discordæ©Ÿèƒ½ã«ã¤ã„ã¦",
            "ç”»åƒç”Ÿæˆã«é–¢ã™ã‚‹è³ªå•",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆ",
            "ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãƒ˜ãƒ«ãƒ—",
            "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªã‚¢ã‚¤ãƒ‡ã‚¢",
            "æŠ€è¡“çš„ãªå•é¡Œè§£æ±º",
            "å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ",
            "æƒ…å ±æ¤œç´¢",
            "å‰µä½œæ´»å‹•æ”¯æ´",
            "ç·åˆçš„ãªç›¸è«‡"
        ]
        
        for i, query in enumerate(search_queries):
            try:
                start_time = time.perf_counter()
                
                result = await memory_system.load_cold_memory(query)
                
                end_time = time.perf_counter()
                execution_time = end_time - start_time
                execution_times.append(execution_time)
                
                # çµæœç¢ºèª
                assert isinstance(result, list)
                assert len(result) <= 10  # max_cold_resultsåˆ¶é™
                
                # APIåˆ¶é™å›é¿ã®ãŸã‚å°ä¼‘æ­¢
                await asyncio.sleep(0.5)
                
            except Exception as e:
                if "quota" in str(e).lower() or "rate" in str(e).lower():
                    print(f"âš ï¸  APIåˆ¶é™ã§ãƒ†ã‚¹ãƒˆä¸­æ–­: {e}")
                    break
                else:
                    raise
        
        if not execution_times:
            pytest.skip("Cold Memory tests skipped due to API limitations")
        
        # çµ±è¨ˆè¨ˆç®—
        avg_time = statistics.mean(execution_times)
        max_time = max(execution_times)
        
        # æ€§èƒ½è¦ä»¶ç¢ºèª
        assert avg_time < 3.0, f"Cold Memoryå¹³å‡æ¤œç´¢æ™‚é–“ç›®æ¨™æœªé”: {avg_time:.4f}s > 3.0s"
        assert max_time < 5.0, f"Cold Memoryæœ€å¤§æ¤œç´¢æ™‚é–“è¨±å®¹ç¯„å›²è¶…é: {max_time:.4f}s > 5.0s"
        
        print(f"\nğŸ“Š Cold Memory Search Performance Report:")
        print(f"   å®Ÿè¡Œå›æ•°: {len(execution_times)}")
        print(f"   å¹³å‡æ¤œç´¢æ™‚é–“: {avg_time:.4f}s")
        print(f"   æœ€å¤§æ¤œç´¢æ™‚é–“: {max_time:.4f}s")
        print(f"   âœ… ç›®æ¨™é”æˆ: <3.0ç§’")
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_embedding_generation_performance_target(self, performance_memory_system):
        """Embeddingç”Ÿæˆæ€§èƒ½ãƒ†ã‚¹ãƒˆ: ç›®æ¨™2.0ç§’ä»¥å†…"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled")
        
        if not os.getenv('GEMINI_API_KEY'):
            pytest.skip("GEMINI_API_KEY required")
        
        memory_system = performance_memory_system
        
        # æ€§èƒ½æ¸¬å®š (5å›å®Ÿè¡Œ - APIåˆ¶é™è€ƒæ…®)
        execution_times = []
        test_texts = [
            "çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ",
            "ä¸­ç¨‹åº¦ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã®æ€§èƒ½è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚" * 5,
            "é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆã€‚" * 20,
            "æ—¥æœ¬èªã®è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã‘ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®é‡è¦æ€§ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚" * 10,
            "technical performance evaluation for embedding generation using text-embedding-004 model"
        ]
        
        for i, text in enumerate(test_texts):
            try:
                start_time = time.perf_counter()
                
                embedding = await memory_system.generate_embedding(text)
                
                end_time = time.perf_counter()
                execution_time = end_time - start_time
                execution_times.append(execution_time)
                
                # çµæœç¢ºèª
                if embedding:
                    assert len(embedding) == 768  # text-embedding-004
                    assert all(isinstance(x, float) for x in embedding)
                
                # APIåˆ¶é™å›é¿
                await asyncio.sleep(1.0)
                
            except Exception as e:
                if "quota" in str(e).lower():
                    print(f"âš ï¸  APIåˆ¶é™ã§ãƒ†ã‚¹ãƒˆä¸­æ–­: {e}")
                    break
                else:
                    raise
        
        if not execution_times:
            pytest.skip("Embedding tests skipped due to API limitations")
        
        # çµ±è¨ˆè¨ˆç®—
        avg_time = statistics.mean(execution_times)
        max_time = max(execution_times)
        
        # æ€§èƒ½è¦ä»¶ç¢ºèª 
        assert avg_time < 2.0, f"Embeddingç”Ÿæˆå¹³å‡æ™‚é–“ç›®æ¨™æœªé”: {avg_time:.4f}s > 2.0s"
        
        print(f"\nğŸ“Š Embedding Generation Performance Report:")
        print(f"   å®Ÿè¡Œå›æ•°: {len(execution_times)}")
        print(f"   å¹³å‡ç”Ÿæˆæ™‚é–“: {avg_time:.4f}s")
        print(f"   æœ€å¤§ç”Ÿæˆæ™‚é–“: {max_time:.4f}s")
        print(f"   âœ… ç›®æ¨™é”æˆ: <2.0ç§’")


class TestMemorySystemScalabilityTests:
    """Memory System ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_multiple_channels_concurrent_access(self):
        """è¤‡æ•°ãƒãƒ£ãƒ³ãƒãƒ«åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled")
        
        memory_system = DiscordMemorySystem(
            redis_url="redis://localhost:6379/13"  # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆå°‚ç”¨
        )
        
        initialized = await memory_system.initialize()
        if not initialized:
            pytest.skip("Memory system initialization failed")
        
        # 10ãƒãƒ£ãƒ³ãƒãƒ«åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
        channels = [f"scale_test_channel_{i}" for i in range(10)]
        
        async def channel_operations(channel_id: str):
            """ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥æ“ä½œ"""
            operations_time = []
            
            for i in range(5):
                # æ›´æ–°æ“ä½œ
                start_time = time.perf_counter()
                await memory_system.update_memory({
                    'messages': [{'role': 'user', 'content': f'{channel_id}_message_{i}'}],
                    'selected_agent': 'scale_agent',
                    'response_content': f'{channel_id}_response_{i}',
                    'channel_id': channel_id,
                    'confidence': 0.8
                })
                
                # èª­ã¿è¾¼ã¿æ“ä½œ
                await memory_system.load_hot_memory(channel_id)
                end_time = time.perf_counter()
                
                operations_time.append(end_time - start_time)
            
            return operations_time
        
        # åŒæ™‚å®Ÿè¡Œ
        start_total = time.perf_counter()
        
        tasks = [channel_operations(channel) for channel in channels]
        results = await asyncio.gather(*tasks)
        
        end_total = time.perf_counter()
        total_time = end_total - start_total
        
        # æ€§èƒ½ç¢ºèª
        all_operation_times = [time for result in results for time in result]
        avg_operation_time = statistics.mean(all_operation_times)
        
        # åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ã§ã‚‚å¹³å‡æ“ä½œæ™‚é–“ãŒ0.2ç§’ä»¥å†…
        assert avg_operation_time < 0.2, f"åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã®æ“ä½œæ™‚é–“ç›®æ¨™æœªé”: {avg_operation_time:.4f}s > 0.2s"
        assert total_time < 10.0, f"å…¨ä½“å®Ÿè¡Œæ™‚é–“ç›®æ¨™æœªé”: {total_time:.2f}s > 10.0s"
        
        print(f"\nğŸ“Š Concurrent Access Performance Report:")
        print(f"   ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(channels)}")
        print(f"   ç·æ“ä½œæ•°: {len(all_operation_times)}")
        print(f"   å¹³å‡æ“ä½œæ™‚é–“: {avg_operation_time:.4f}s")
        print(f"   ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}s")
        print(f"   âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ç›®æ¨™é”æˆ")
        
        await memory_system.cleanup()
    
    @pytest.mark.performance
    @pytest.mark.asyncio 
    async def test_memory_system_resource_usage(self):
        """Memory System ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""
        if not os.getenv('PERFORMANCE_TESTS_ENABLED'):
            pytest.skip("Performance tests disabled")
        
        memory_system = DiscordMemorySystem(
            redis_url="redis://localhost:6379/12"  # ãƒªã‚½ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆå°‚ç”¨
        )
        
        initialized = await memory_system.initialize()
        if not initialized:
            pytest.skip("Memory system initialization failed")
        
        # å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ
        test_channel = "resource_test_channel"
        
        # 1000ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
        start_time = time.perf_counter()
        
        for i in range(1000):
            await memory_system.update_memory({
                'messages': [{'role': 'user', 'content': f'ãƒªã‚½ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ{i}'}],
                'selected_agent': 'resource_agent',
                'response_content': f'ãƒªã‚½ãƒ¼ã‚¹å¿œç­”{i}',
                'channel_id': test_channel,
                'confidence': 0.7
            })
            
            # 100ä»¶ã”ã¨ã«èª­ã¿è¾¼ã¿
            if i % 100 == 0:
                await memory_system.load_hot_memory(test_channel)
        
        end_time = time.perf_counter()
        total_processing_time = end_time - start_time
        
        # çµ±è¨ˆç¢ºèª
        stats = await memory_system.get_memory_stats()
        
        # æ€§èƒ½è¦ä»¶
        assert total_processing_time < 60.0, f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚é–“ç›®æ¨™æœªé”: {total_processing_time:.2f}s > 60.0s"
        assert stats['status'] == 'connected'
        
        print(f"\nğŸ“Š Resource Usage Test Report:")
        print(f"   å‡¦ç†ä»¶æ•°: 1000ä»¶")
        print(f"   ç·å‡¦ç†æ™‚é–“: {total_processing_time:.2f}s")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {total_processing_time/1000:.4f}s/ä»¶")
        print(f"   Hot Memoryä½¿ç”¨é‡: {stats['hot_memory']['total_messages']}ä»¶")
        print(f"   âœ… ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§ç›®æ¨™é”æˆ")
        
        await memory_system.cleanup()


# æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè£œåŠ©
if __name__ == "__main__":
    print("âš¡ Memory System Performance Tests")
    print("é«˜è² è·æ€§èƒ½ãƒ†ã‚¹ãƒˆã®ãŸã‚ã€å°‚ç”¨ç’°å¢ƒã§ã®å®Ÿè¡Œã‚’æ¨å¥¨")
    print("")
    print("å®Ÿè¡Œä¾‹:")
    print("export PERFORMANCE_TESTS_ENABLED=1")
    print("export GEMINI_API_KEY=your_api_key")
    print("docker-compose up -d")
    print("python -m pytest tests/performance/test_memory_performance.py -v -s --tb=short")
    print("")
    print("æ€§èƒ½ç›®æ¨™:")
    print("- Hot Memory: <0.1ç§’")
    print("- Cold Memory: <3.0ç§’")
    print("- Embedding: <2.0ç§’")