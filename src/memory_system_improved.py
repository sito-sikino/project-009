"""
Improved Memory System with Production Enhancements
æœ¬ç•ªç’°å¢ƒå‘ã‘æ”¹å–„ç‰ˆMemory System
"""

import os
import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

import redis.asyncio as redis
import asyncpg
from langchain_google_genai import GoogleGenerativeAIEmbeddings


# Custom Exceptions
class MemorySystemError(Exception):
    """Memory SystemåŸºæœ¬ã‚¨ãƒ©ãƒ¼"""
    pass

class RedisConnectionError(MemorySystemError):
    """Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class PostgreSQLConnectionError(MemorySystemError):
    """PostgreSQLæ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class EmbeddingQuotaError(MemorySystemError):
    """Embedding APIåˆ¶é™ã‚¨ãƒ©ãƒ¼"""
    pass

class EmbeddingError(MemorySystemError):
    """Embeddingç”Ÿæˆã‚¨ãƒ©ãƒ¼"""
    pass


class RateLimiter:
    """API Rate Limiter"""
    def __init__(self, calls_per_second: float = 1.0):
        self.min_interval = 1.0 / calls_per_second
        self.last_called = 0.0
        self._lock = asyncio.Lock()
    
    async def acquire(self):
        async with self._lock:
            current_time = asyncio.get_event_loop().time()
            elapsed = current_time - self.last_called
            if elapsed < self.min_interval:
                await asyncio.sleep(self.min_interval - elapsed)
            self.last_called = asyncio.get_event_loop().time()


@dataclass
class HealthStatus:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    redis_connected: bool = False
    postgres_connected: bool = False
    embeddings_available: bool = False
    last_check: Optional[datetime] = None
    error_count: int = 0
    
    @property
    def is_healthy(self) -> bool:
        return all([self.redis_connected, self.postgres_connected, self.embeddings_available])


class ImprovedDiscordMemorySystem:
    """
    æœ¬ç•ªç’°å¢ƒå¯¾å¿œæ”¹å–„ç‰ˆMemory System
    
    æ”¹å–„ç‚¹:
    - ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
    - è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
    - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†
    - æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–
    """
    
    def __init__(self, 
                 redis_url: str = None, 
                 postgres_url: str = None,
                 gemini_api_key: str = None):
        # ãƒ­ã‚®ãƒ³ã‚°è¨­å®šï¼ˆæœ€åˆã«åˆæœŸåŒ–ï¼‰
        self.logger = self._setup_logging()
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å®‰å…¨ã«å–å¾—
        self.redis_url = redis_url or os.getenv('REDIS_URL', 'redis://localhost:6379')
        self.postgres_url = self._sanitize_postgres_url(
            postgres_url or os.getenv('POSTGRESQL_URL', '')
        )
        
        # Google Embeddingsè¨­å®š
        self.embeddings_client = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            google_api_key=gemini_api_key or os.getenv('GEMINI_API_KEY'),
            task_type="RETRIEVAL_DOCUMENT"
        )
        
        # æ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.redis: Optional[redis.Redis] = None
        self.redis_pool: Optional[redis.ConnectionPool] = None
        self.postgres_pool: Optional[asyncpg.Pool] = None
        
        # è¨­å®š
        self.hot_memory_limit = 20
        self.hot_memory_ttl = 86400
        self.embedding_model = "models/text-embedding-004"
        self.similarity_threshold = 0.7
        self.max_cold_results = 10
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ (15 RPM = 0.25 RPS)
        self.embedding_rate_limiter = RateLimiter(calls_per_second=0.25)
        
        # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self.health_status = HealthStatus()
    
    def _sanitize_postgres_url(self, url: str) -> str:
        """PostgreSQL URL ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰éš è”½ï¼‰"""
        if not url:
            return 'postgresql://localhost:5432/discord_agent'
        
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰éƒ¨åˆ†ã‚’éš ã™
        if '@' in url and '://' in url:
            parts = url.split('@')
            if len(parts) == 2:
                cred_part = parts[0].split('://')[-1]
                if ':' in cred_part:
                    user = cred_part.split(':')[0]
                    sanitized = f"{parts[0].split('://')[0]}://{user}:****@{parts[1]}"
                    self.logger.info(f"PostgreSQL URL (sanitized): {sanitized}")
        
        return url
    
    def _setup_logging(self) -> logging.Logger:
        """æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
        logger = logging.getLogger(__name__)
        logger.setLevel(os.getenv('LOG_LEVEL', 'INFO'))
        
        # æ§‹é€ åŒ–ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s - %(extra)s'
        )
        
        handler = logging.StreamHandler()
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    async def initialize(self) -> bool:
        """Memory SystemåˆæœŸåŒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        try:
            # Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
            self.redis_pool = redis.ConnectionPool.from_url(
                self.redis_url,
                max_connections=10,
                decode_responses=True,
                encoding="utf-8",
                retry_on_timeout=True,
                socket_timeout=5.0,
                socket_connect_timeout=5.0
            )
            self.redis = redis.Redis(connection_pool=self.redis_pool)
            
            # Redisæ¥ç¶šç¢ºèª
            await self.redis.ping()
            self.health_status.redis_connected = True
            self.logger.info("âœ… Redis Hot Memory connected with connection pool")
            
            # PostgreSQLæ¥ç¶šãƒ—ãƒ¼ãƒ«ï¼ˆæ”¹å–„ç‰ˆè¨­å®šï¼‰
            self.postgres_pool = await asyncpg.create_pool(
                self.postgres_url,
                min_size=2,
                max_size=10,
                max_queries=50000,
                max_inactive_connection_lifetime=300.0,
                command_timeout=30,
                server_settings={
                    'jit': 'off',
                    'application_name': 'discord_agent_memory',
                    'statement_timeout': '30s',
                    'lock_timeout': '10s'
                }
            )
            
            # PostgreSQL & pgvectorç¢ºèª
            async with self.postgres_pool.acquire() as conn:
                # pgvectoræ‹¡å¼µç¢ºèª
                extensions = await conn.fetch(
                    "SELECT extname FROM pg_extension WHERE extname = 'vector'"
                )
                if not extensions:
                    raise PostgreSQLConnectionError("pgvector extension not found")
                
                await conn.fetchval('SELECT 1')
                self.health_status.postgres_connected = True
            
            self.logger.info("âœ… PostgreSQL Cold Memory connected with pgvector")
            
            # Embeddings APIç¢ºèª
            self.health_status.embeddings_available = True
            
            # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
            self.health_status.last_check = datetime.now()
            self.health_status.error_count = 0
            
            self.logger.info("ğŸ§  Discord Memory System initialized successfully")
            return True
            
        except redis.RedisError as e:
            self.logger.error(f"âŒ Redis initialization failed: {e}")
            raise RedisConnectionError(f"Redis connection failed: {e}")
            
        except asyncpg.PostgresError as e:
            self.logger.error(f"âŒ PostgreSQL initialization failed: {e}")
            raise PostgreSQLConnectionError(f"PostgreSQL connection failed: {e}")
            
        except Exception as e:
            self.logger.error(f"âŒ Memory System initialization failed: {e}")
            self.health_status.error_count += 1
            return False
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type(redis.RedisError)
    )
    async def load_hot_memory(self, channel_id: str) -> List[Dict[str, Any]]:
        """Hot Memoryèª­ã¿è¾¼ã¿ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        try:
            if not self.redis:
                if not await self.initialize():
                    return []
            
            redis_key = f"channel:{channel_id}:messages"
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½¿ç”¨ã§åŠ¹ç‡åŒ–
            async with self.redis.pipeline(transaction=False) as pipe:
                pipe.lrange(redis_key, 0, self.hot_memory_limit - 1)
                pipe.expire(redis_key, self.hot_memory_ttl)
                results = await pipe.execute()
            
            messages = results[0] if results else []
            
            # JSON ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
            hot_memory = []
            for msg_json in messages:
                try:
                    msg_data = json.loads(msg_json)
                    hot_memory.append(msg_data)
                except json.JSONDecodeError as e:
                    self.logger.warning(f"Invalid JSON in hot memory: {e}")
                    continue
            
            self.logger.debug(
                f"Hot Memory loaded",
                extra={"channel_id": channel_id, "message_count": len(hot_memory)}
            )
            return hot_memory
            
        except redis.RedisError as e:
            self.logger.error(f"Hot Memory load failed: {e}")
            self.health_status.redis_connected = False
            raise RedisConnectionError(f"Redis read failed: {e}")
    
    async def load_cold_memory(self, query: str, channel_id: str = None) -> List[Dict[str, Any]]:
        """Cold Memoryæ¤œç´¢ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰"""
        try:
            # TEMPORARY FIX: PostgreSQLé–¢æ•°æœªä½œæˆã®ãŸã‚ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            self.logger.info("ğŸ”§ Cold Memory temporarily disabled (PostgreSQL function missing)")
            return []
            
            # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            cold_memory = []
            for row in results:
                cold_memory.append({
                    'memory_id': str(row['memory_id']),
                    'content': row['content'],
                    'similarity': float(row['similarity']),
                    'created_at': row['created_at'].isoformat(),
                    'selected_agent': row['selected_agent'],
                    'importance_score': float(row['importance_score'])
                })
            
            self.logger.info(
                f"Cold Memory search completed",
                extra={
                    "query_length": len(query),
                    "results_count": len(cold_memory),
                    "channel_id": channel_id
                }
            )
            return cold_memory
            
        except asyncpg.PostgresError as e:
            self.logger.error(f"Cold Memory search failed: {e}")
            self.health_status.postgres_connected = False
            raise PostgreSQLConnectionError(f"PostgreSQL search failed: {e}")
        
        except Exception as e:
            self.logger.error(f"Cold Memory load failed: {e}")
            return []
    
    async def update_memory_transactional(self, conversation_data: Dict[str, Any]) -> bool:
        """Memoryæ›´æ–°ï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ä¿è¨¼ï¼‰"""
        try:
            channel_id = conversation_data.get('channel_id')
            if not channel_id:
                return False
            
            # Redisæ›´æ–°ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            memory_entry = {
                'timestamp': datetime.now().isoformat(),
                'messages': conversation_data.get('messages', []),
                'selected_agent': conversation_data.get('selected_agent'),
                'response_content': conversation_data.get('response_content'),
                'confidence': conversation_data.get('confidence', 0.5),
                'channel_id': channel_id
            }
            
            redis_key = f"channel:{channel_id}:messages"
            
            # PostgreSQLæ›´æ–°ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            messages = conversation_data.get('messages', [])
            if not messages:
                return True  # Redisã®ã¿æ›´æ–°
            
            latest_message = messages[-1] if messages else {}
            user_content = latest_message.get('content', '')
            
            if not user_content:
                return True  # Redisã®ã¿æ›´æ–°
            
            # Embeddingç”Ÿæˆ
            content_embedding = await self.generate_embedding_with_rate_limit(user_content)
            response_embedding = await self.generate_embedding_with_rate_limit(
                conversation_data.get('response_content', '')
            )
            
            # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            success = False
            
            # Redisæ›´æ–°
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.lpush(redis_key, json.dumps(memory_entry))
                pipe.ltrim(redis_key, 0, self.hot_memory_limit - 1)
                pipe.expire(redis_key, self.hot_memory_ttl)
                await pipe.execute()
            
            # PostgreSQLæ›´æ–°ï¼ˆEmbedingãŒç”Ÿæˆã§ããŸå ´åˆã®ã¿ï¼‰
            if content_embedding and response_embedding:
                async with self.postgres_pool.acquire() as conn:
                    async with conn.transaction():
                        await conn.execute("""
                            INSERT INTO memories (
                                guild_id, channel_id, user_id, message_id,
                                original_content, processed_content,
                                selected_agent, agent_response, confidence,
                                content_embedding, response_embedding,
                                conversation_context, importance_score
                            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
                        """,
                            int(conversation_data.get('guild_id', 0)),
                            int(channel_id),
                            int(conversation_data.get('user_id', 0)),
                            int(conversation_data.get('message_id', 0)),
                            user_content,
                            user_content,
                            conversation_data.get('selected_agent', 'unknown'),
                            conversation_data.get('response_content', ''),
                            conversation_data.get('confidence', 0.5),
                            content_embedding,
                            response_embedding,
                            json.dumps(conversation_data),
                            min(conversation_data.get('confidence', 0.5), 1.0)
                        )
            
            success = True
            self.logger.info(
                "Memory updated successfully",
                extra={"channel_id": channel_id}
            )
            return success
            
        except Exception as e:
            self.logger.error(f"Memory update failed: {e}")
            return False
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((EmbeddingError, EmbeddingQuotaError))
    )
    async def generate_embedding_with_rate_limit(self, text: str) -> Optional[List[float]]:
        """Embeddingç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
        try:
            if not text.strip():
                return None
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            await self.embedding_rate_limiter.acquire()
            
            # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾å¿œ
            max_chars = 2048 * 4
            truncated_text = text[:max_chars] if len(text) > max_chars else text
            
            # éåŒæœŸå®Ÿè¡Œ
            embedding = await asyncio.to_thread(
                self.embeddings_client.embed_query, 
                truncated_text
            )
            
            return embedding
            
        except Exception as e:
            error_str = str(e).lower()
            if "quota" in error_str or "rate" in error_str:
                self.logger.warning(f"Embedding API quota/rate limit: {e}")
                raise EmbeddingQuotaError(f"API quota exceeded: {e}")
            else:
                self.logger.error(f"Embedding generation failed: {e}")
                raise EmbeddingError(f"Embedding failed: {e}")
    
    async def get_health_status(self) -> Dict[str, Any]:
        """è©³ç´°ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            # Rediså¥åº·ç¢ºèª
            if self.redis:
                try:
                    await self.redis.ping()
                    self.health_status.redis_connected = True
                except:
                    self.health_status.redis_connected = False
            
            # PostgreSQLå¥åº·ç¢ºèª
            if self.postgres_pool:
                try:
                    async with self.postgres_pool.acquire() as conn:
                        await conn.fetchval('SELECT 1')
                    self.health_status.postgres_connected = True
                except:
                    self.health_status.postgres_connected = False
            
            # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
            self.health_status.last_check = datetime.now()
            
            return {
                "status": "healthy" if self.health_status.is_healthy else "unhealthy",
                "redis": self.health_status.redis_connected,
                "postgres": self.health_status.postgres_connected,
                "embeddings": self.health_status.embeddings_available,
                "last_check": self.health_status.last_check.isoformat() if self.health_status.last_check else None,
                "error_count": self.health_status.error_count
            }
            
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹æ­£å¸¸çµ‚äº†"""
        try:
            if self.redis:
                await self.redis.close()
                await self.redis_pool.disconnect() if self.redis_pool else None
                self.logger.info("Redis connection closed")
            
            if self.postgres_pool:
                await self.postgres_pool.close()
                self.logger.info("PostgreSQL pool closed")
                
        except Exception as e:
            self.logger.error(f"Cleanup failed: {e}")


# Factoryé–¢æ•°
def create_improved_memory_system() -> ImprovedDiscordMemorySystem:
    """æ”¹å–„ç‰ˆMemory Systemç”Ÿæˆ"""
    return ImprovedDiscordMemorySystem(
        redis_url=os.getenv('REDIS_URL'),
        postgres_url=os.getenv('POSTGRESQL_URL'),
        gemini_api_key=os.getenv('GEMINI_API_KEY')
    )